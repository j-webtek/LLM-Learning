# üìò LLM-Learning 

Welcome to LLM-Learning! This repository is dedicated to offering a curated collection of intriguing research papers, innovative projects, and insightful documents from the world of Large Language Models (LLMs) and beyond. LLMs have transformed the AI landscape with their ability to understand and generate human-like text. Here, we gather some of the most notable works that provide insights into their capabilities, applications, and potential impact. Whether you're a seasoned researcher, a developer looking to harness the power of LLMs, or just a curious enthusiast, there's something for everyone. Dive into the transformative capabilities of LLMs and discover their potential across diverse applications.

---

üìà Repository Statistics

Research Papers: 8

Projects: 10

Links & Articles: 52.

---
üÜï ## Latest Additions **10/2/23**

Today's advancements in AI and technology have showcased a plethora of innovations and strategic moves. The introduction of Flash Attention promises to revolutionize attention mechanisms, making them faster and more memory-efficient, a boon for NLP tasks. Meanwhile, the capabilities of AI continue to expand, as demonstrated by Bing's ability to interpret captchas through prompt-visual engineering. On the research front, a new approach in text-to-image model personalization has been introduced, emphasizing textual scene decomposition for enhanced image synthesis. In a significant strategic move, the NSA is establishing an AI security center to fortify defenses against global threats, with a keen focus on AI model protection. The AI community is also buzzing about the potential of decentralizing Large Language Models, advocating for a blockchain-like system to ensure data privacy and reproducibility. Microsoft's exploration into nuclear energy for its AI endeavors signifies the tech giant's commitment to sustainable and powerful computing. In the realm of LLMs, the StreamingLLM framework is breaking barriers, allowing for efficient processing of infinite sequence lengths. Lastly, the release of Stable LM 3B, a compact yet powerful language model, is set to bring high-performance AI capabilities to portable devices. These insights underscore the rapid pace of AI development and its ever-growing impact across various sectors.

### üîó Links & Articles

- **[Introduction to Flash Attention: A Breakthrough in Efficient Attention Mechanism](https://medium.com/@sthanikamsanthosh1994/introduction-to-flash-attention-a-breakthrough-in-efficient-attention-mechanism-3eb47e8962c3)**: Flash Attention is a groundbreaking advancement in attention mechanisms, offering a faster and more memory-efficient solution compared to traditional methods.

- **[captcha with Bing](https://twitter.com/literallydenis/status/1708283962399846459)**: I've tried to read the captcha with Bing, and it is possible after some prompt-visual engineering.

- **[Break-A-Scene: Extracting Multiple Concepts from a Single Image](https://omriavrahami.com/break-a-scene/)**: Text-to-image model personalization seeks to incorporate user-provided concepts into models for diverse synthesis.

- **[National Security Agency is starting an artificial intelligence security center](https://apnews.com/article/nsa-artificial-intelligence-security-deepfakes-f9b19dd64890884cc2b0700ddf66e666)**: The NSA is launching an AI security center to bolster defense and intelligence systems against threats.

- **[Decentralized Artificial Intelligence](https://www.chaos-engineering.dev/p/decentralized-artificial-intelligence)**: The article discusses the need for decentralization in Large Language Models (LLMs) and AI.

- **[Microsoft is going nuclear to power its AI ambitions](https://www.theverge.com/2023/9/26/23889956/microsoft-next-generation-nuclear-energy-smr-job-hiring)**: Microsoft is exploring the potential of next-generation nuclear reactors to power its data centers and support its AI initiatives.

- **[Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm)** ([Research Paper](https://arxiv.org/abs/2309.17453)): Deploying LLMs in streaming applications presents challenges, including memory consumption and handling longer texts.

- **[Introducing Stable LM 3B: Bringing Sustainable, High-Performance Language Models to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices)**: Stable LM 3B, a compact 3 billion parameter language model, operates efficiently on portable devices.

- **[Released L2E OS v0.1 "Temple DOS" . A new OS on the block! The first OS that boots to AI!](https://twitter.com/VulcanIgnis/status/1708851772435968017)**: A new operating system that boots directly to an AI interface.

---

## üöÄ Quick Navigation

1. [Visual Diagrams](#visual-diagrams)
2. [Research Papers](#research-papers)
3. [Projects](#projects)
4. [Links & Articles](#links--articles)
5. [License](#license)

---

## üìä Visual Diagrams

For a pictorial insight:
- [Data to LLM Processes](Data%20to%20LLM%20Processes.pdf)
- [Foundation Models](Foundation%20Models.pdf)
- [LLM Stack](LLM%20Stack.pdf)
- [Multi_Models](Multi_Models.pdf)

---

## üìÑ Research Papers

Dive deep into the world of research with these enlightening papers:

### üíº Applications and Deployment

- **Large Language Models for Compiler Optimization**
  - üìú [Read the Paper](https://arxiv.org/pdf/2309.07062.pdf)
  - üìù A study on the use of Large Language Models for code optimization.

- **PROMPT2MODEL: Generating Deployable Models from Natural Language Instructions**
  - üìú [Read the Paper](https://arxiv.org/pdf/2308.12261.pdf)
  - üìù A method that transforms natural language task descriptions into deployable models.

### üìä Data Handling and Annotation

- **AnnoLLM: Making Large Language Models to Be Better**
  - üìú [Read the Paper](https://www.semanticscholar.org/reader/70da4fb798a86cbe8cad96c27ced0415885bbd9d)
  - üìù Large language models (LLMs) like GPT-3.5 can serve as effective crowdsourced annotators when given sufficient guidance and example demonstrations.

- **Want To Reduce Labeling Cost? GPT-3 Can Help**
  - üìú [Read the Paper](https://www.semanticscholar.org/reader/70da4fb798a86cbe8cad96c27ced0415885bbd9d)
  - üìù The study explores using GPT-3 as a cost-effective data labeler for training other models in NLP tasks.

- **DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions**
  - üìú [Read the Paper](https://aclanthology.org/2023.acl-long.573.pdf)
  - üìù The study introduces the task of recommending datasets based on a short natural language description of a research idea.

### üé® Graphics and Imaging

- **CoRF: Colorizing Radiance Fields using Knowledge Distillation**
  - üìú [Read the Paper](https://arxiv.org/abs/2309.07668)
  - üìù This research introduces a method to generate colorized novel views from input grayscale multi-view images using Neural Radiance Fields (NeRF). The proposed distillation-based technique effectively transfers color knowledge from 2D colorization methods to the radiance field network, ensuring 3D consistency and producing superior results in both indoor and outdoor scenes compared to other methods.

### üöÄ Retrieval Techniques

- **Precise Zero-Shot Dense Retrieval without Relevance Labels**
  - üìú [Read the Paper](https://aclanthology.org/2023.acl-long.99.pdf)
  - üìù Introduction of Hypothetical Document Embeddings (HyDE) for zero-shot dense retrieval.

---

## üõ†Ô∏è Projects

### üí° Model Optimization & Fine-Tuning

#### Data Cleaning and Labeling
- üåü **Cleanlab** - An aid for cleaning data and labels in ML datasets. [Check it out](https://github.com/cleanlab/cleanlab).

#### Model Adaptation and Fine-Tuning
- üåü **LLaMa-Adapter** - A lightweight adaptation method for fine-tuning Instruction-following and Multi-modal LLaMA models. [Learn more](https://github.com/OpenGVLab/LLaMA-Adapter).
- üåü **axolotl** - A tool designed to streamline the fine-tuning of AI models. [Check it out](https://github.com/OpenAccess-AI-Collective/axolotl).

### üåê Multimodal Models & Applications

#### Curated Lists and Collections
- üåü **Awesome-Multimodal-Large-Language-Models** - A curated list of Multimodal Large Language Models. [Explore here](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models).

#### Frameworks and Systems
- üåü **DreamLLM** - A learning framework focusing on synergy between multimodal comprehension and creation. [Dive in](https://github.com/RunpeiDong/DreamLLM).
- üåü **NExT-GPT** - The first end-to-end MM-LLM for text, image, video, and audio. [Discover more](https://github.com/NExT-GPT/NExT-GPT).

### üõçÔ∏è Collections & Repositories

#### LLM Collections and Demonstrations
- üåü **LargeLanguageModelsProjects** - A collection of llama models in different configurations. [Explore](https://github.com/MuhammadMoinFaisal/LargeLanguageModelsProjects/blob/main/Chat%20with%20Multiple%20Documents/Chat_with_Multiple_Documents_Llama2_OpenAI_Chroma_comp.ipynb).

#### Toolkits and Utilities
- üåü **LiteLLM** - Manages inputs to the provider's completion and embedding endpoints. [Discover](https://github.com/BerriAI/litellm).
- üåü **AutoGPT** - A modular toolkit for AI agents. [Explore on GitHub](https://github.com/Significant-Gravitas/AutoGPT).
- üåü **localGPT** - Interact with documents locally ensuring data privacy. [Check it out on GitHub](https://github.com/PromtEngineer/localGPT).
- üåü **LLM-Finetuning-Hub** - Resources for finetuning LLMs tailored to specific use cases. [Learn more on GitHub](https://github.com/georgian-io/LLM-Finetuning-Hub).
- üåü **chatgpt-history-export-to-md** - Convert your ChatGPT history and data export into neatly formatted Markdown files. It includes YAML headers and a Code interpreter for Advanced Data Analysis. [Check it out on GitHub](https://github.com/mohamed-chs/chatgpt-history-export-to-md).

---

## üîó Links & Articles

### üìà Research & Innovations

- [Introduction to Flash Attention: A Breakthrough in Efficient Attention Mechanism](https://medium.com/@sthanikamsanthosh1994/introduction-to-flash-attention-a-breakthrough-in-efficient-attention-mechanism-3eb47e8962c3): Flash Attention is a groundbreaking advancement in attention mechanisms, offering a faster and more memory-efficient solution compared to traditional methods.
- [Break-A-Scene: Extracting Multiple Concepts from a Single Image](https://omriavrahami.com/break-a-scene/): Text-to-image model personalization seeks to incorporate user-provided concepts into models for diverse synthesis.
- [Efficient Streaming Language Models with Attention Sinks](https://github.com/mit-han-lab/streaming-llm) ([Research Paper](https://arxiv.org/abs/2309.17453)): Deploying LLMs in streaming applications presents challenges, including memory consumption and handling longer texts.
- [Introducing Stable LM 3B: Bringing Sustainable, High-Performance Language Models to Smart Devices](https://stability.ai/blog/stable-lm-3b-sustainable-high-performance-language-models-smart-devices): Stable LM 3B, a compact 3 billion parameter language model, operates efficiently on portable devices.
- [MuZero: Mastering Go, chess, shogi and Atari without rules](https://www.deepmind.com/blog/muzero-mastering-go-chess-shogi-and-atari-without-rules): DeepMind's MuZero represents a significant advancement in AI, mastering games like Go, chess, shogi, and Atari without being pre-informed of the rules, showcasing its capability to strategize in unknown environments. Going beyond previous AI models, MuZero learns only the vital aspects of its environment and combines this with a look-ahead tree search, setting new performance standards while potentially leading to applications in real-world scenarios where rules are undefined.
- [Anand Katti](https://www.linkedin.com/posts/anand-katti-4278637_ai-genai-llm-activity-7097479600368160768-jNzj/) - LLMOps enhances the MLOps framework by introducing LLM-specific tasks.
- [An Introduction to LLMOps: Operationalizing and Managing Large Language Models using Azure ML](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/an-introduction-to-llmops-operationalizing-and-managing-large/ba-p/3910996) - Large language models (LLMs) like GPT-4 have transformed natural language processing with their superior performance, but their real-world deployment requires a systematic approach called LLMOps.
- [GPT-4V (ision) System Card](https://cdn.openai.com/papers/GPTV_System_Card.pdf) - GPT-4 with Vision (GPT-4V) combines text and image processing, expanding the impact of language-only systems.
- [Our Humble Attempt at ‚ÄúHow Much Data Is Needed to Fine-Tune‚Äù](https://barryzhang.substack.com/p/our-humble-attempt-at-fine-tuning) - Researchers experiment with the OpenAI fine-tuning API, revealing that GPT-3.5 can achieve near GPT-4 performance in specialized tasks.
- [Falcon 180B: Can It Run on Your Computer?](https://kaitchup.substack.com/p/falcon-180b-can-it-run-on-your-computer) - The Technology Innovation Institute (TII) introduces Falcon 180B, a massive 180 billion parameter model, emphasizing its memory requirements.

### üåå General AI Insights

#### AI Model Philosophies and Debates
- [First Impressions with GPT-4V(ision)](https://blog.roboflow.com/gpt-4-vision/): OpenAI has introduced GPT-4V, a multimodal extension of the GPT-4 model, allowing users to input images and voice queries. While the model excels at general image questions, providing context-aware answers, it has limitations, including inaccuracies in object detection and occasional "hallucinations" of incorrect information.
- [Why Open Source AI Will Win](https://varunshenoy.substack.com/p/why-open-source-ai-will-win) - The debate between open-source and closed-source AI models.
- [NSA, FBI, and CISA Release Cybersecurity Information Sheet on Deepfake Threats](https://www.cisa.gov/news-events/alerts/2023/09/12/nsa-fbi-and-cisa-release-cybersecurity-information-sheet-deepfake-threats): The NSA, FBI, and CISA have released a Cybersecurity Information Sheet on the rising threat of synthetic media, including deepfakes, highlighting their growing impact on sectors like the NSS, DoD, and national infrastructure. The agencies emphasize the importance of reviewing their recommended steps and best practices to address deepfake threats effectively.

#### AI Technologies and Capabilities
- [Released L2E OS v0.1 "Temple DOS" . A new OS on the block! The first OS that boots to AI!](https://twitter.com/VulcanIgnis/status/1708851772435968017): A new operating system that boots directly to an AI interface.
- [Decentralized Artificial Intelligence](https://www.chaos-engineering.dev/p/decentralized-artificial-intelligence): The article discusses the need for decentralization in Large Language Models (LLMs) and AI.
- [Microsoft is going nuclear to power its AI ambitions](https://www.theverge.com/2023/9/26/23889956/microsoft-next-generation-nuclear-energy-smr-job-hiring): Microsoft is exploring the potential of next-generation nuclear reactors to power its data centers and support its AI initiatives.
- [Run any ML model from any programming language](https://carton.run/): Carton is a tool that packages machine learning models with metadata in a zip file without altering the original model, simplifying the model deployment process by automatically selecting the appropriate runner based on the metadata. Once packed, Carton's framework-agnostic API facilitates model inference, with the software built in Rust and offering bindings to multiple languages.
- [The next generation of smart glasses](https://www.meta.com/smart-glasses/): Ray-Ban and Meta collaborate on sunglasses that video record, and image capture, and can be queried via Meta‚Äôs AI
- [Vectorize: a vector database for shipping AI-powered applications to production, fast](https://blog.cloudflare.com/vectorize-vector-database-open-beta/): Vectorize is a new vector database from Cloudflare designed to help machine learning models "remember" and enhance AI-powered applications. It allows developers to build full-stack AI applications on Cloudflare's global network, enhancing semantic search, classification, recommendation, and anomaly detection use-cases. Vectorize is in open beta and integrates with Cloudflare Workers, enabling it to power various applications, including improving LLMs' accuracy and context, and supporting embeddings from platforms like OpenAI and Cohere.
- [Workers AI: serverless GPU-powered inference on Cloudflare‚Äôs global network](https://blog.cloudflare.com/workers-ai/): Cloudflare is launching Workers AI, a platform that allows developers to run AI models using a few lines of code without managing infrastructure, emphasizing accessibility, serverless operation, and privacy. The service offers popular open-source AI models, ensures data privacy by default, and will soon expand its model offerings through a partnership with Hugging Face, with plans for rapid GPU rollout across global data centers by 2024.
- [You can give ChatGPT a picture of your team‚Äôs whiteboarding session and have it write the code for you.](https://twitter.com/mckaywrigley/status/1707101465922453701?s=20): This is absolutely insane.
- [Mistral 7B](https://mistral.ai/news/announcing-mistral-7b/): Mistral 7B, a 7.3B parameter model, outperforms various Llama versions on benchmarks, excels in both code and English tasks, and uses efficient attention mechanisms for better performance. Available under the Apache 2.0 license, it's easy to deploy across platforms, and a fine-tuned chat variant surpasses Llama 2 13B chat in performance.
- [AI startup Lamini bets future on AMD's Instinct GPUs](https://www.theregister.com/2023/09/26/amd_instinct_ai_lamini/): AI startup Lamini has chosen to exclusively use AMD's Instinct GPUs for its platform that refines large language models (LLMs), setting itself apart from many competitors that rely on Nvidia's hardware. While Lamini's platform has garnered interest from major companies like Amazon and Walmart, AMD's focus on expanding its software ecosystem and forthcoming hardware upgrades aim to make its AI accelerators more attractive and accessible to developers and businesses.
- [Vicious Self-Degradation](https://twitter.com/8teapi/status/1706520893621784780): When a frequent query is Googled, Quora identifies it, uses ChatGPT to generate an answer that may contain a hallucination, and this ChatGPT-generated response becomes the top Google answer.
- [Inside the Matrix: Visualizing Matrix Multiplication, Attention and Beyond](https://pytorch.org/blog/inside-the-matrix/): The article introduces "mm", a visualization tool designed to display matrix multiplications (matmuls), which are foundational to machine learning models. Using three-dimensional visualizations, "mm" enables clearer understanding of complex matrix operations and compositions, especially benefiting visual thinkers, and covers various topics from basic matrix operations to the intricate workings of GPT-2 attention heads, demonstrating the benefits of this geometric approach to understanding algebraic properties in matrix computations.
- [Can you beat a stochastic parrot?](https://parrotchess.com/): Play chess against GPT-3.5.

#### Ethical and Societal Implications of AI
- [National Security Agency is starting an artificial intelligence security center](https://apnews.com/article/nsa-artificial-intelligence-security-deepfakes-f9b19dd64890884cc2b0700ddf66e666): The NSA is launching an AI security center to bolster defense and intelligence systems against threats.
- [WebGPU Technical Report](https://chromium.googlesource.com/chromium/src/+/main/docs/security/research/graphics/webgpu_technical_report.md): WebGPU introduces extensive attack surfaces to Chrome's GPU process, including the core WebGPU, third-party Usermode Graphics Drivers, and shader compilers, emphasizing the complexity that may result in vulnerabilities. Despite significant efforts to validate input and extensive fuzzing, there remain concerns about potential vulnerabilities in areas like Dawn's use-after-frees, callbacks, the Chrome Command Buffer, and the SwiftShader JIT compiler, indicating a need for ongoing vigilance and manual audits. assistance 24/7 without human intervention, though human volunteers remain available for more nuanced assistance.
- [Be My AI](https://www.bemyeyes.com/blog/announcing-be-my-ai): Be My Eyes, a platform connecting volunteers with visually impaired users, has integrated an AI feature called "Be My AI" to assist with everyday tasks and is now launching it in an open beta phase for iOS users, with an Android version in the pipeline. "Be My AI" allows users to take photos and receive detailed descriptions, proving invaluable for tasks like reading labels, organizing wardrobes, and getting visual assistance 24/7 without human intervention, though human volunteers remain available for more nuanced assistance.
- [Signal‚Äôs Meredith Whittaker: AI is fundamentally ‚Äòa surveillance technology‚Äô](https://techcrunch.com/2023/09/25/signals-meredith-whittaker-ai-is-fundamentally-a-surveillance-technology/): Meredith Whittaker, Signal's president, emphasized at TechCrunch Disrupt 2023 that AI is fundamentally a surveillance technology, deeply intertwined with the big data and targeting industry dominated by tech giants. While acknowledging not all AI applications are exploitative, she highlighted the inherent surveillance nature of AI and the economic drivers behind facial recognition technology, noting that beneficial uses, like face blurring in Signal's app, are overshadowed by more intrusive applications driven by profit motives.

#### AI in Education
- [Student Use Cases for AI](https://hbsp.harvard.edu/inspiring-minds/student-use-cases-for-ai): Generative AI tools, particularly large language models (LLMs), present both opportunities and challenges in educational settings, offering students and educators unparalleled access to powerful AI systems. As AI becomes increasingly prevalent in classrooms, it's crucial for educators and students to understand the potential benefits, biases, and privacy concerns of AI, and to adopt best practices for interacting with these tools to ensure effective and safe usage.

#### LLM Architectures and Applications
- [OpenAI](https://twitter.com/openai/status/1707077710047216095?s=46&t=Tn3eky5MQ9AEY1npL2msJw): ChatGPT can now browse the internet to provide you with current and authoritative information, complete with direct links to sources. It is no longer limited to data before September 2021.
- [RAG is more than just embedding search](https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/) - Potential of Retrieval Augmented Generation (RAG) in LLMs.
- [Emerging Architectures for LLM Applications](https://a16z.com/emerging-architectures-for-llm-applications/) - The article presents an architecture for applications using large language models (LLMs).
- [Essential Guide to Foundation Models and Large Language Models](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404) - Foundation models explained.

#### Best Practices and Guidelines
- [Practical insights and best practices for Fine Tuned LLM based use cases for Governed Enterprises](https://3ai.in/practical-insights-and-best-practices-for-fine-tuned-llm-based-use-cases-for-governed-enterprises/) - Aditya Khandekar's article on 3AI discusses best practices for deploying Large Language Models (LLMs) in enterprise settings.
- [Why You (Probably) Don‚Äôt Need to Fine-tune an LLM](https://www.tidepool.so/2023/08/17/why-you-probably-dont-need-to-fine-tune-an-llm/) - This article guides those building applications with Large Language Models (LLMs), emphasizing that while many consider fine-tuning LLMs to enhance performance, there are often simpler and more effective alternatives.

#### AI in Multimedia and Collaboration
- [captcha with Bing](https://twitter.com/literallydenis/status/1708283962399846459): I've tried to read the captcha with Bing, and it is possible after some prompt-visual engineering.
- [What codegen is (actually) good for](https://www.figma.com/blog/what-codegen-is-actually-good-for/#aAkZ9): Codegen, the automatic generation of code based on predefined rules, is gaining popularity, with tools ranging from simple code completion in IDEs to advanced AI-driven systems. While many developers use AI for code generation, skepticism remains about its accuracy; instead of viewing codegen as a full replacement, it's best seen as an extension of a developer, assisting in the design-to-development process by suggesting suitable tools, speeding up workflows, and acting as a reference, though it won't entirely replace established team patterns.
- [Introducing New AI Experiences Across Our Family of Apps and Devices](https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/): Meta is introducing a range of AI-driven features, including AI stickers for image editing on apps like Instagram, the advanced conversational assistant 'Meta AI' for multiple platforms, and 28 additional AIs with distinct personalities, some portrayed by celebrities. As they expand AI offerings for businesses and developers, they acknowledge potential challenges and emphasize a cautious approach with built-in safeguards.
- [Getty made an AI generator that only trained on its licensed images](https://www.theverge.com/2023/9/25/23884679/getty-ai-generative-image-platform-launch) - Getty Images collaborated with Nvidia to introduce a tool allowing users to produce images from its extensive library, ensuring full copyright indemnification.
- [ChatGPT can now see, hear, and speak](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak) - ChatGPT introduces new voice and image capabilities, emphasizing user safety, privacy, and understanding model limitations.
- [Expanding access to safer AI with Amazon](https://www.anthropic.com/index/anthropic-amazon) - Amazon's collaboration with Anthropic aims to create industry-leading foundation models and make advanced models like Claude 2 accessible through Amazon Bedrock.

### üõ†Ô∏è Tools & Databases

#### LLM Databases and Search Engines
- [Guide to Chroma DB | A Vector Store for Generative AI LLMs](https://www.analyticsvidhya.com/blog/2023/07/guide-to-chroma-db-a-vector-store-for-your-generative-ai-llms/) - An introduction to Chroma DB, a vector database for LLMs.
- [Build AI search into your applications](https://www.elastic.co/elasticsearch/elasticsearch-relevance-engine) - Introduction to the Elasticsearch Relevance Engine‚Ñ¢ for AI-based search.

#### LLM Integration and APIs
- [Llama API](https://python.langchain.com/docs/integrations/chat/llama_api) - This notebook shows how to use LangChain with LlamaAPI.

#### LLM Toolkits and Platforms
- [Embedchain](https://docs.embedchain.ai/quickstart) - Start building LLM-powered bots in under 30 seconds.
- [Two-Tower Embedding Model](https://www.hopsworks.ai/dictionary/two-tower-embedding-model) - A training approach aligning embeddings from two modalities, like images and text, useful for personalized recommendation systems.

### üìö Tutorials & How-Tos

- [How to make history with LLMs & other generative models](https://leighmariebraswell.substack.com/p/how-to-make-history-with-llms-and): The author discusses the transformative potential of Large Language Models (LLMs), highlighting promising startup ideas in areas like developer tooling and knowledge worker augmentation, while expressing skepticism about general consumer search and some SaaS replacements. On the infrastructure side, running large models locally and providing compute for model training are seen as promising, but ventures into observability and vector databases face more challenges.
- [A poor man's guide to fine-tuning Llama 2](https://duarteocarmo.com/blog/fine-tune-llama-2-telegram): The author details the ease and efficiency of fine-tuning the Llama 2 model to simulate conversations from their personal
- [Building a Knowledge base for custom LLMs](https://cismography.medium.com/building-a-knowledge-base-for-custom-llms-using-langchain-chroma-and-gpt4all-950906ae496d) - How to build a knowledge base for custom LLMs.
- [Fine-Tuning LLMs: LoRA or Full-Parameter?](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) - A comparison of full-parameter fine-tuning and LoRA for Llama 2 models.
- [Building a Scalable Pipeline for LLMs and RAG](https://ai.plainenglish.io/building-a-scalable-pipeline-for-large-language-models-and-rag-an-overview-7cb93a03f657) - Constructing a scalable pipeline for LLMs and RAG.
- [How to run a llama, alpaca, vicuna REST API for AI Discord Bot, Part 1](https://www.youtube.com/watch?v=PMFf9FwPN70&ab_channel=Janek) - How to set up a llama.cpp python binding server to host an API for LLM and how to create a python script for discord bot.
- [A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU&ab_channel=JeremyHoward) - Jeremy Howard covers foundational concepts, evaluations of GPT-4, and practical applications of modern language models.
- [Spotify‚Äôs AI Voice Translation Pilot Means Your Favorite Podcasters Might Be Heard in Your Native Language](https://newsroom.spotify.com/2023-09-25/ai-voice-translation-pilot-lex-fridman-dax-shepard-steven-bartlett/) - Spotify pilots a new feature using AI to translate podcasts while retaining the original speaker's voice and style.


---

## üîñ License

All content in this repository is shared under the MIT License. Please refer to the LICENSE file for more details.
