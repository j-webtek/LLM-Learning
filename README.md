# 📘 LLM-Learning 

Welcome to LLM-Learning! Dive into a curated collection of intriguing research papers, innovative projects, and insightful documents from the world of Large Language Models and beyond.

---

## 🚀 Quick Navigation

1. [Visual Diagrams](#📊-visual-diagrams)
2. [Research Papers](#📄-research-papers)
3. [Projects](#🛠️-projects)
4. [Links & Articles](#🔗-links--articles)
5. [License](#🔖-license)

---

## 📊 Visual Diagrams

For a pictorial insight:
- [Data to LLM Processes](Data%20to%20LLM%20Processes.pdf)
- [Foundation Models](Foundation%20Models.pdf)
- [LLM Stack](LLM%20Stack.pdf)
- [Multi_Models](Multi_Models.pdf)

---

## 📄 Research Papers

Dive deep into the world of research with these enlightening papers:

### 🗓️ September 22, 2023:

- **Large Language Models for Compiler Optimization**
  - 📜 [Read the Paper](https://arxiv.org/pdf/2309.07062.pdf)
  - 📝 A study on the use of Large Language Models for code optimization.

- **PROMPT2MODEL: Generating Deployable Models from Natural Language Instructions**
  - 📜 [Read the Paper](https://arxiv.org/pdf/2308.12261.pdf)
  - 📝 A method that transforms natural language task descriptions into deployable models.

- **Precise Zero-Shot Dense Retrieval without Relevance Labels**
  - 📜 [Read the Paper](https://aclanthology.org/2023.acl-long.99.pdf)
  - 📝 Introduction of Hypothetical Document Embeddings (HyDE) for zero-shot dense retrieval.

---

## 🛠️ Projects

### 💡 Model Optimization & Fine-Tuning
- 🌟 **Cleanlab** - An aid for cleaning data and labels in ML datasets. [Check it out](https://github.com/cleanlab/cleanlab).
- 🌟 **LLaMa-Adapter** - A lightweight adaptation method for fine-tuning Instruction-following and Multi-modal LLaMA models. [Learn more](https://github.com/OpenGVLab/LLaMA-Adapter).
- 🌟 **axolotl** - A tool designed to streamline the fine-tuning of AI models. [Check it out](https://github.com/OpenAccess-AI-Collective/axolotl).

### 🌐 Multimodal Models & Applications
- 🌟 **Awesome-Multimodal-Large-Language-Models** - A curated list of Multimodal Large Language Models. [Explore here](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models).
- 🌟 **DreamLLM** - A learning framework focusing on synergy between multimodal comprehension and creation. [Dive in](https://github.com/RunpeiDong/DreamLLM).
- 🌟 **NExT-GPT** - The first end-to-end MM-LLM for text, image, video, and audio. [Discover more](https://github.com/NExT-GPT/NExT-GPT).

### 🛍️ Collections & Repositories
- 🌟 **LargeLanguageModelsProjects** - A collection of llama models in different configurations. [Explore](https://github.com/MuhammadMoinFaisal/LargeLanguageModelsProjects/blob/main/Chat%20with%20Multiple%20Documents/Chat_with_Multiple_Documents_Llama2_OpenAI_Chroma_comp.ipynb).
- 🌟 **LiteLLM** - Manages inputs to the provider's completion and embedding endpoints. [Discover](https://github.com/BerriAI/litellm).

---

## 🔗 Links & Articles

### 🌌 General AI Insights
- [Why Open Source AI Will Win](https://varunshenoy.substack.com/p/why-open-source-ai-will-win) - The debate between open-source and closed-source AI models.
- [RAG is more than just embedding search](https://jxnl.github.io/instructor/blog/2023/09/17/rag-is-more-than-just-embedding-search/) - Potential of Retrieval Augmented Generation (RAG) in LLMs.

### 🛠️ Tools & Databases
- [Guide to Chroma DB | A Vector Store for Generative AI LLMs](https://www.analyticsvidhya.com/blog/2023/07/guide-to-chroma-db-a-vector-store-for-your-generative-ai-llms/) - An introduction to Chroma DB, a vector database for LLMs.
- [Build AI search into your applications](https://www.elastic.co/elasticsearch/elasticsearch-relevance-engine) - Introduction to the Elasticsearch Relevance Engine™ for AI-based search.

### 📚 Tutorials & How-Tos
- [Building a Knowledge base for custom LLMs](https://cismography.medium.com/building-a-knowledge-base-for-custom-llms-using-langchain-chroma-and-gpt4all-950906ae496d) - How to build a knowledge base for custom LLMs.
- [Fine-Tuning LLMs: LoRA or Full-Parameter?](https://www.anyscale.com/blog/fine-tuning-llms-lora-or-full-parameter-an-in-depth-analysis-with-llama-2) - A comparison of full-parameter fine-tuning and LoRA for Llama 2 models.
- [Building a Scalable Pipeline for LLMs and RAG](https://ai.plainenglish.io/building-a-scalable-pipeline-for-large-language-models-and-rag-an-overview-7cb93a03f657) - Constructing a scalable pipeline for LLMs and RAG.

---

## 🔖 License

This repository is licensed under the MIT License. Dive into the [`LICENSE`](LICENSE) file for more details.
